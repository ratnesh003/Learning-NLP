{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratnesh003/Learning-NLP/blob/main/Assignment%207/nlp_ui21cs48_lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLKtsaWWWRDD",
        "outputId": "ea167c1e-298d-4671-fb8a-26fd9432f141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pprint, time\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
      ],
      "metadata": {
        "id": "ZN-g_NNJWZEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "train_set, test_set = train_test_split(data, train_size=0.95, test_size=0.05)\n",
        "\n",
        "print(\"Training Set Length -\", len(train_set))\n",
        "print(\"Testing Set Length -\", len(test_set))\n",
        "print(\"-\" * 100)\n",
        "print(\"Training Data -\\n\")\n",
        "print(train_set[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IHTcRz2WbGG",
        "outputId": "dec22923-ce9c-4532-c738-ed9056eecf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Length - 3718\n",
            "Testing Set Length - 196\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Training Data -\n",
            "\n",
            "[[('Pro-forma', 'ADJ'), ('balance', 'NOUN'), ('sheets', 'NOUN'), ('clearly', 'ADV'), ('show', 'VERB'), ('why', 'ADV'), ('Cray', 'NOUN'), ('Research', 'NOUN'), ('favored', 'VERB'), ('the', 'DET'), ('spinoff', 'NOUN'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('minimum-wage', 'NOUN'), ('bill', 'NOUN'), ('worked', 'VERB'), ('out', 'PRT'), ('*', 'X'), ('by', 'ADP'), ('Congress', 'NOUN'), ('and', 'CONJ'), ('Bush', 'NOUN'), ('won', 'VERB'), ('easy', 'ADJ'), ('approval', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('House', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Klauser', 'NOUN'), ('says', 'VERB'), ('0', 'X'), ('Mitsui', 'NOUN'), ('has', 'VERB'), ('75', 'NUM'), ('U.S.', 'NOUN'), ('subsidiaries', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('it', 'PRON'), ('holds', 'VERB'), ('35', 'NUM'), ('%', 'NOUN'), ('interest', 'NOUN'), ('or', 'CONJ'), ('more', 'ADJ'), ('*T*-1', 'X'), ('and', 'CONJ'), ('the', 'DET'), ('trading', 'NOUN'), ('company', 'NOUN'), ('hopes', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('double', 'VERB'), ('the', 'DET'), ('number', 'NOUN'), ('of', 'ADP'), ('its', 'PRON'), ('U.S.', 'NOUN'), ('affiliates', 'NOUN'), ('in', 'ADP'), ('1990', 'NUM'), ('.', '.')], [('The', 'DET'), ('``', '.'), ('one-yen', 'ADJ'), (\"''\", '.'), ('controversy', 'NOUN'), ('first', 'ADV'), ('came', 'VERB'), ('to', 'PRT'), ('a', 'DET'), ('head', 'NOUN'), ('last', 'ADJ'), ('week', 'NOUN'), ('when', 'ADV'), ('the', 'DET'), ('city', 'NOUN'), ('of', 'ADP'), ('Hiroshima', 'NOUN'), ('announced', 'VERB'), ('that', 'ADP'), ('Fujitsu', 'NOUN'), ('won', 'VERB'), ('a', 'DET'), ('contract', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('design', 'VERB'), ('a', 'DET'), ('computer', 'NOUN'), ('system', 'NOUN'), ('0', 'X'), ('*T*-2', 'X'), ('to', 'PRT'), ('map', 'VERB'), ('its', 'PRON'), ('waterworks', 'NOUN'), ('*T*-1', 'X'), ('.', '.')], [('Whereas', 'ADP'), ('conventional', 'ADJ'), ('securities', 'NOUN'), ('financings', 'NOUN'), ('are', 'VERB'), ('structured', 'VERB'), ('*-3', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('sold', 'VERB'), ('*-1', 'X'), ('quickly', 'ADV'), (',', '.'), ('Wall', 'NOUN'), ('Street', 'NOUN'), (\"'s\", 'PRT'), ('new', 'ADJ'), ('penchant', 'NOUN'), ('for', 'ADP'), ('leveraged', 'ADJ'), ('buy-outs', 'NOUN'), ('and', 'CONJ'), ('junk', 'NOUN'), ('bonds', 'NOUN'), ('is', 'VERB'), ('resulting', 'VERB'), ('in', 'ADP'), ('long-term', 'ADJ'), ('lending', 'VERB'), ('commitments', 'NOUN'), ('that', 'DET'), ('*T*-2', 'X'), ('stretch', 'VERB'), ('out', 'PRT'), ('for', 'ADP'), ('months', 'NOUN'), ('or', 'CONJ'), ('years', 'NOUN'), ('.', '.')], [('Serial', 'ADJ'), ('bonds', 'NOUN'), ('are', 'VERB'), ('priced', 'VERB'), ('*-1', 'X'), ('at', 'ADP'), ('par', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('yield', 'VERB'), ('from', 'ADP'), ('6.40', 'NUM'), ('%', 'NOUN'), ('in', 'ADP'), ('1991', 'NUM'), ('to', 'PRT'), ('7.15', 'NUM'), ('%', 'NOUN'), ('in', 'ADP'), ('1999', 'NUM'), ('.', '.')], [('Its', 'PRON'), ('entrenched', 'VERB'), ('49', 'NUM'), ('stock', 'NOUN'), ('specialists', 'NOUN'), ('firms', 'NOUN'), ('are', 'VERB'), ('fighting', 'VERB'), ('tooth', 'NOUN'), ('and', 'CONJ'), ('nail', 'NOUN'), ('against', 'ADP'), ('programs', 'NOUN'), ('.', '.')], [('For', 'ADP'), ('an', 'DET'), ('American', 'ADJ'), ('reader', 'NOUN'), (',', '.'), ('part', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('charm', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('engaging', 'ADJ'), ('novel', 'NOUN'), ('should', 'VERB'), ('come', 'VERB'), ('in', 'ADP'), ('*', 'X'), ('recognizing', 'VERB'), ('that', 'ADP'), ('Japan', 'NOUN'), ('is', 'VERB'), (\"n't\", 'ADV'), ('the', 'DET'), ('buttoned-down', 'ADJ'), ('society', 'NOUN'), ('of', 'ADP'), ('contemporary', 'ADJ'), ('American', 'ADJ'), ('lore', 'NOUN'), ('.', '.')], [('But', 'CONJ'), ('any', 'DET'), ('potential', 'ADJ'), ('acquirer', 'NOUN'), ('must', 'VERB'), ('attempt', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('reach', 'VERB'), ('some', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('accord', 'NOUN'), ('with', 'ADP'), ('the', 'DET'), ('company', 'NOUN'), (\"'s\", 'PRT'), ('employees', 'NOUN'), (',', '.'), ('primarily', 'ADV'), ('its', 'PRON'), ('pilots', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('powerful', 'ADJ'), ('machinists', 'NOUN'), (\"'\", 'PRT'), ('union', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('has', 'VERB'), ('opposed', 'VERB'), ('a', 'DET'), ('takeover', 'NOUN'), ('.', '.')], [('The', 'DET'), ('percentage', 'NOUN'), ('of', 'ADP'), ('lung', 'NOUN'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('the', 'DET'), ('workers', 'NOUN'), ('at', 'ADP'), ('the', 'DET'), ('West', 'NOUN'), ('Groton', 'NOUN'), (',', '.'), ('Mass.', 'NOUN'), (',', '.'), ('paper', 'NOUN'), ('factory', 'NOUN'), ('appears', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('the', 'DET'), ('highest', 'ADJ'), ('for', 'ADP'), ('any', 'DET'), ('asbestos', 'NOUN'), ('workers', 'NOUN'), ('studied', 'VERB'), ('*', 'X'), ('in', 'ADP'), ('Western', 'ADJ'), ('industrialized', 'VERB'), ('countries', 'NOUN'), (',', '.'), ('he', 'PRON'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
        "print(\"Train Tagged Words - \", len(train_tagged_words))\n",
        "\n",
        "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
        "print(\"Train Tagged Words - \", len(test_tagged_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAJaH5uaWcip",
        "outputId": "937b7738-aa56-4828-f9bc-ab848a1ce24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tagged Words -  95418\n",
            "Train Tagged Words -  5258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tagged_tokens = [tag[0] for tag in train_tagged_words]\n",
        "train_tagged_tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQxiTcyJWeDq",
        "outputId": "e91a7718-29b3-4b21-9809-c962a16cc274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pro-forma',\n",
              " 'balance',\n",
              " 'sheets',\n",
              " 'clearly',\n",
              " 'show',\n",
              " 'why',\n",
              " 'Cray',\n",
              " 'Research',\n",
              " 'favored',\n",
              " 'the']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tagged_pos_tokens = [tag[1] for tag in train_tagged_words]\n",
        "train_tagged_pos_tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-HyLYqVWfuX",
        "outputId": "b82cd4bf-2a12-495e-bb62-d816653229a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ADJ', 'NOUN', 'NOUN', 'ADV', 'VERB', 'ADV', 'NOUN', 'NOUN', 'VERB', 'DET']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_vocabulary_set = set(train_tagged_tokens)\n"
      ],
      "metadata": {
        "id": "du_gGmq7WhJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_pos_tag_set = set(train_tagged_pos_tokens)"
      ],
      "metadata": {
        "id": "aVihMJM4WieV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
        "    tag_list = [pair for pair in train_bag if pair[1] == tag]\n",
        "    tag_count = len(tag_list)\n",
        "    word_given_tag_list = [pair[0] for pair in tag_list if pair[0] == word]\n",
        "    word_given_tag_count = len(word_given_tag_list)\n",
        "\n",
        "    return (word_given_tag_count, tag_count)"
      ],
      "metadata": {
        "id": "M8LdDnJwWkEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
        "    tags = [pair[1] for pair in train_bag]\n",
        "\n",
        "    t1_tags_list = [tag for tag in tags if tag == t1]\n",
        "    t1_tags_count = len(t1_tags_list)\n",
        "\n",
        "    t2_given_t1_list = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
        "    t2_given_t1_count = len(t2_given_t1_list)\n",
        "\n",
        "    return(t2_given_t1_count, t1_tags_count)"
      ],
      "metadata": {
        "id": "rDE4TRxZWld6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_pos_tags = len(training_pos_tag_set)\n",
        "len_vocab = len(training_vocabulary_set)\n",
        "\n",
        "tags_matrix = np.zeros((len_pos_tags, len_pos_tags), dtype='float32')\n",
        "for i, t1 in enumerate(list(training_pos_tag_set)):\n",
        "    for j, t2 in enumerate(list(training_pos_tag_set)):\n",
        "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
      ],
      "metadata": {
        "id": "LHjw2w38Wm81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_df = pd.DataFrame(tags_matrix, columns = list(training_pos_tag_set), index=list(training_pos_tag_set))"
      ],
      "metadata": {
        "id": "uaEhQHBMWoPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Vanilla_Viterbi(words, train_bag = train_tagged_words):\n",
        "    state = []\n",
        "\n",
        "    T = list(set([pair[1] for pair in train_bag]))\n",
        "\n",
        "    for key, word in enumerate(words):\n",
        "        p = []\n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[state[-1], tag]\n",
        "\n",
        "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
        "            state_probability = emission_p * transition_p\n",
        "            p.append(state_probability)\n",
        "\n",
        "        pmax = max(p)\n",
        "        state_max = T[p.index(pmax)]\n",
        "        state.append(state_max)\n",
        "    return list(zip(words, state))"
      ],
      "metadata": {
        "id": "8L36b0y3WpvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_test_1 = 'I want to play football'\n",
        "words = word_tokenize(sentence_test_1)\n",
        "tagged_seq = Vanilla_Viterbi(words)\n",
        "print(tagged_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfjzo4UTWrFL",
        "outputId": "4330f06b-8dae-480a-9d14-62a7c4575117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRON'), ('want', 'VERB'), ('to', 'PRT'), ('play', 'VERB'), ('football', 'NOUN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_test_2='The children played games in the park'\n",
        "words = word_tokenize(sentence_test_2)\n",
        "tagged_seq = Vanilla_Viterbi(words)\n",
        "print(tagged_seq)"
      ],
      "metadata": {
        "id": "XDCSnisvWsUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2ab08e-acd7-44f6-d800-f0792c1702fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DET'), ('children', 'NOUN'), ('played', 'VERB'), ('games', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('park', 'NOUN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_test_2='I was busy talking to others.'\n",
        "words = word_tokenize(sentence_test_2)\n",
        "tagged_seq = Vanilla_Viterbi(words)\n",
        "print(tagged_seq)"
      ],
      "metadata": {
        "id": "yYDDLucxc1JE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3961b86d-fe12-48e2-c0fb-a4a757877b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRON'), ('was', 'VERB'), ('busy', 'ADJ'), ('talking', 'VERB'), ('to', 'PRT'), ('others', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiPgbjTvdGBg",
        "outputId": "44548cf5-149b-44e2-95ee-1dea9bf20a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/ML/spam.csv'\n",
        "dataset = pd.read_csv(file_path,encoding='latin-1')"
      ],
      "metadata": {
        "id": "Y_bylv8zdIDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "predicted_tags_list = []\n",
        "size = len(dataset['v2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXpLppflddUA",
        "outputId": "ed161b3b-2eca-4efb-b3a5-6956cb09ca4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_tags_list = []\n",
        "size = len(dataset['v2'])\n",
        "print(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcBoygojfBMw",
        "outputId": "45616d6c-0865-489d-ad95-a5fd6fa45ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['v2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnZBanFtj0va",
        "outputId": "280cb0fe-b347-4a83-a25e-d02413c19347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       Go until jurong point, crazy.. Available only ...\n",
            "1                           Ok lar... Joking wif u oni...\n",
            "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       U dun say so early hor... U c already then say...\n",
            "4       Nah I don't think he goes to usf, he lives aro...\n",
            "                              ...                        \n",
            "5567    This is the 2nd time we have tried 2 contact u...\n",
            "5568              Will ï¿½_ b going to esplanade fr home?\n",
            "5569    Pity, * was in mood for that. So...any other s...\n",
            "5570    The guy did some bitching but I acted like i'd...\n",
            "5571                           Rofl. Its true to its name\n",
            "Name: v2, Length: 5572, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_test_2= dataset['v2'][0]\n",
        "words = word_tokenize(sentence_test_2)\n",
        "tagged_seq = Vanilla_Viterbi(words)\n",
        "print(tagged_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQmN_OyTfDfz",
        "outputId": "4a284684-3b75-468f-dcf0-a33c7407ece2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Go', 'ADJ'), ('until', 'ADP'), ('jurong', 'ADJ'), ('point', 'NOUN'), (',', '.'), ('crazy', 'ADJ'), ('..', 'ADJ'), ('Available', 'ADJ'), ('only', 'ADV'), ('in', 'ADP'), ('bugis', 'ADJ'), ('n', 'ADJ'), ('great', 'ADJ'), ('world', 'NOUN'), ('la', 'DET'), ('e', 'ADJ'), ('buffet', 'NOUN'), ('...', '.'), ('Cine', 'ADJ'), ('there', 'DET'), ('got', 'VERB'), ('amore', 'ADJ'), ('wat', 'ADJ'), ('...', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWt0s4FaKlZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}